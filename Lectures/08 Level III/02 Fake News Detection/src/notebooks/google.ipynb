{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google scraping settings\n",
    "FETCH_GOOGLE_LINKS_RETRIES = 1\n",
    "FETCH_GOOGLE_LINKS_SELECTORS = [\n",
    "    \"div.g a\",        # Very generic fallback\n",
    "]\n",
    "\n",
    "NO_GOOGLE_SEARCH_RESULTS_MESSAGES = [\n",
    "    \"did not match any documents\",\n",
    "    \"no results found for\",\n",
    "    \"did not match any web results\",\n",
    "    \"no results found for\",\n",
    "    \"make sure all words are spelled correctly\",\n",
    "    \"try different keywords\",\n",
    "    \"try more general keywords\",\n",
    "    \"try fewer keywords\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_google_results(self, query: str) -> tuple[str, bool, list[str]]:\n",
    "    \"\"\"Fetch Google search results for an author.\"\"\"\n",
    "    url = f\"https://www.google.com/search?q={query}\"\n",
    "\n",
    "    links = []\n",
    "    no_result = False\n",
    "    retry_count = 0\n",
    "    while not links and retry_count < FETCH_GOOGLE_LINKS_RETRIES:\n",
    "        response = send_request(url=url)\n",
    "\n",
    "        for message in NO_GOOGLE_SEARCH_RESULTS_MESSAGES:\n",
    "            if message in response.text:\n",
    "                no_result = True\n",
    "                break\n",
    "\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        for selector in FETCH_GOOGLE_LINKS_SELECTORS:\n",
    "            results = soup.select(selector)\n",
    "            if results:\n",
    "                for result in results:\n",
    "                    href = result.get(\"href\")\n",
    "                    if href and href.startswith(\"http\") and \"google.com\" not in href:\n",
    "                        links.append(href)\n",
    "                break  # Stop if we found results\n",
    "        retry_count += 1\n",
    "\n",
    "    # Remove any duplicate links and limit to top 10 while keeping the order\n",
    "    links = list(dict.fromkeys(links))[:10]\n",
    "    return response.text, no_result, links"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
